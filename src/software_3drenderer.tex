\section{3D Renderer}
The 3D renderer is an uncanny combination of proper 3D techniques and screen space tricks. A summary inspection of its main function (\cw{R\_RenderPlayerView}) reveals it is capable to render three things.\\
\par
\ccode{R_RenderPlayerView.c}{}
\par
\begin{itemize}
	\item Segments (walls and portals which are always vertical).
	\item Flats (ceilings and floors which are always horizontal).
	\item Things (also called "Masked") which are not only monsters, weapons, ammo, and sprites but also partially transparent walls.
\end{itemize}
 Its most breathtaking aspect of it is its ability to renders walls and flats with zero overdraw. Sprites and Transparent walls do introduce a little bit of overdraw but it is minimal.\\
\par
The full life of a frame can be summarized as follow:
\begin{itemize}
\item Render walls segments, sorted front to back from the player point of view. Both wall ends are projected into screenspace axis X. Based on the distance and floor/ceiling the wall sectors belongs to, calculate a column Y offset and an height. 
\item To render a full wall, generate a set of columns to make ends meet. Interpolate height and Y vertical columns. While rendering:
   \begin{itemize}
     \item record screenspace vertical gaps between walls or between wall and screen boundaries. Infer ceiling (if above mid-screen) or floor (if below miscreen) and stored the area into an array of structure called "visplanes".
     \item Store sprites to be drawn into an array of struct "vissprites".
   \end{itemize}      
\item Render all ceiling and floors from the visplanes.
\item Render transparent elements in back to front order.
\item Render player sprite (the weapon the marine is holding).
\end{itemize}
\par
The most important part (and what \doom engine is most famous for) is the ability to sort walls and things extremely efficiently thanks to its Binary Space Partition tree. Interestingly, there is a bit of a back story about how the BSP came to be a central part of the game engine.\\
\par
\pagebreak
%\trivia{Wolfenstein 3D and Doom have orthogonal architectures. Where the former tried to draw everything vertically to favor the VGA, the latter tried to draw everything horizontally to favor the 486 cachelines.}

% \subsection{Walls}
% There are two ways to render walls in a correct way. Either go with a painter algorithm which draw far to near and involves no book-keeping but generate a lot of overdraw. Or draw near to far, keeping track of what has been drawn which is more compicated but has zero overdraw. In both strategy lies the problem of sorting them according to the player point of view. Given the high cost of rendition, \doom went for the latter approach.\\
% \par

% \subsubsection{Sorting walls}
In its early instance the engine consumed exactly what the designer produced, namely lines and sectors. Starting in the sector containing the player, the engine would look for double sided lines and treat them as portals, traversing the map in a back to front fashion. Each portal lead to adjacent sector where the process was repeated recursively\footnote{That was the same design Ken Silverman's build engine would settle on to power Duke Nukem 3D. However in 1996 Pentium had taken over and were more than able to deal with complex polygons.}.\\
\par
\srawpngdrawing{0.7}{duke_map}
\vspace{1cm}
\fq{The engine was built out of "sectors" -- complex polygonal regions with a common floor / ceiling texture and height, but it didn't have the BSP-chopped "subsectors".  It started in the view sector and recursively flowed into the adjourning sectors, but because they could all be complex polygons it was a lot of record keeping to know what parts you had already visited or were in the stack somewhere.  It worked, and simple areas were fast, but it slowed down precipitously with complexity.}{John Carmack}
\par
Things indeed slowed down significantly with a particular map of John Romero creation.\\
\par
\fq{I was working on E1M2 around April 1993, and I created a set of circular stairs. John C. wrote the renderer with a sector list to know what should be rendered. The problem is that this set of stairs made his sector list building code take a really long amount of time to execute because the same sectors needed to be put into the list over and over due to how the algorithm worked.}{John Romero}\\
\par
\fullimage{SCREEN01.png}%{Notice the HUD using a huge portion of the 3D canvas.} 
\label{HUD_screenshot}
\par
As the news that the technology was not good enough to ship, around the same time an other very serious issue arose.\\
\par
Back in August 1992, id Software had landed a contract with Nintendo to port Wolfenstein 3D to SNES. They subcontracted the project and forgot about it to focus on \doom. In April 1994, the contractor was nowhere in sight. They had nothing to deliver to Nintendo. It was a big deal involving a huge penalty.\\
\par
 Development for \doom stopped completely as the team desperately banged they old game together into a machine not remotely built to do what they wanted. While Tom Halls dusted of his 6502 assembly skills, John Carmack had a different kind of problem at hand, the raycasting technology which Wolfenstein relied on was too much for the Nintendo console. The SNES and its 6503 on steroids simply did not have enough juice for the DDA algorithm\footnote{You can read everything about DDA in Game Engine Black Book: Wolfenstein 3D}.\\% It turned out a white paper co-authored by Bruce Naylor would end up making a huge difference.\\
\par



\fq{John started searching around for 3D research papers. He had several VHS tapes of math conferences, and compendiums of graphics papers from conferences because game books were a rare thing back then, and there was nothing printed that could help us create the engine we were building -- he had to figure out where to get information that was not directly applicable to games and figure out how to adapt it to his problem.\\
\par
Bruce Naylor's May 1993 AT\&T Bell Labs paper was titled "Constructing Good Partitioning Trees" and was published in the proceedings of Graphics Interface '93. John had this book in his collection. Bruce's explanation of BSPs was mostly to cull backfaces from 3D models, but the algorithm seemed like the right direction, so John adapted it for Wolfenstein 3D.}{John Romero}\\
\par
\fq{I do remember clearly that I first used BSP for the SNES version of Wolfenstein, which was a gentle introduction with everything being axial and easier to visualize, which gave me more confidence I would be able to make it work when I went back to working on Doom}{John Carmack}\\
% Concave and convex sectors proved to be too much complexity for the engine to deal with and maintain a descent frame rate. This was a huge issue. They did not have much time to work on it thought, since around the same time this issue was discovered, work on \doom had to stop in order to respond to an emergency.\\
% \par
With a visual surface determination not based on raycasting but rather on BSP, Wolfenstein 3D SNES managed to reach an acceptable framerate\footnote{}. Within three weeks the managed to produce "something".\\
\par
Due to Nintendo strict non-violence policy the game had to be heavily censored to reach a child-friendly quality. Blood was replaced with sweat. guard dogs are replaced with mutant rats and Hitler was renamed "Staatmeister" (which translates to State Master).\\
\par
And with that problem solved, by the end of April, the whole team was back on \doom.
\pagebreak

\cfullimage{bsp_paper.png}{Bruce Naylor's paper: "Constructing Good Partitioning Trees"}
\pagebreak

\subsection{Binary Space Partitioning: Theory} \label{Binary Space Partitioning: Theory}
Binary Space Partitioning trees have many applications. The one we are interested in is how \doom uses them to perform VSD (Visible Surface Determination). Bruce Naylor's thesis paper "ON VISIBLE SURFACE GENERATION BY A PRIORITI TREE STRUCTURES" features a pretty good summary.\\

 \begin{verbatim}
In order to determine the visible surface at each pixel, traditionally
tile distance from the viewing position to each polygon which maps onto 
that pixel is calculated. Most methods attempt to minimize the number 
of polygons to be so considered. Our approach eliminates these distance
calculations entirely. Rather, it transforms the polygonal data base 
(splitting polygons when necessary) into a binary tree which can be 
traversed at image generation time to yield a visible priority z value
for each polygon.
\end{verbatim}

\par
\fq{When I did the early work on BSPs\footnote{That was while working on Quake, John and Bruce met only after \doom shipped.}, Bruce Naylor came down and visited here and gave me copies of a bunch of his papers. It's interesting to talk to people about the old days. Of course, you've got the Internet now. You can find anything nowadays. But back then, it was really something to get reprints of old academic papers. There were some clearinghouses I used to use: you'd pay twenty-five dollars or whatever, and they'd mail you xeroxes of old research papers. It was just a very, very different world. I learned most of my programming when I had a grand total of like three reference books. You had to figure everything else yourself. So I was finding I was reinventing a lot of classic things, like Huffman encoding or LZW encoding. So I'd be all proud of myself for having figured something out, and then I'd find it was just classic method and they did it better than I did.}{John Carmack, Interview for Scarydarkfast}\\
\par
To understand how BSPs work, let's take the example of a map which could easily have been created with DoomED.\\
\par
 For simplicity the map we will be working with is made of eight vertices linked together to form a room made of four walls (\cw{A}, \cw{B}, \cw{C}, and \cw{D}). Inside the room a pillar which is also made of four walls (\cw{E}, \cw{F}, \cw{G}, and \cw{G}). The map is made of only one complex sector (it has a hole in it). Despite is simplicity it is obvious how it is a difficult problem to solve to a renderer since depending on the point of view the order in which the wall must be drawn will vary. A naive solution would require a complex sorting algorithm. Notice that all lines have a direction and all lines have only one side (on their right side).\\

\par
\rawdrawing{doom_map}
\par
To build the BSP from the map, the core idea is to repeatedly select a line to spit the map in two. Split lines become \cw{SEGMENTS} and split sectors become {SUB-SECTORS}.\\ 
\par
In our example, a list of poor choices of splitters would be \cw{A}, then \cw{B}, \cw{C}, and \cw{D} since they would not divide data well.\\ 
\par
Let's say our heuristic selected line \cw{H} which conveniently cut  the room in half. Some lines are entirely on the left of H and some are entirely on its right. Lines on both sides must be slit into segments.  After the split, the two leaves in the BSP contains two sub-sectors. One is convex (\cw{\{A, B1, H D1\}}) and will not be touched anymore. The other one is concave (\cw{\{E, F, G, B2, C, D2\}}) and will need further splitting. The process is repeated until all subsectors are convex.\\
\par
\drawing{doom_map_split1}{}
\par
The process is repeated until every node is reduced to a convex sub-space. Notice how the binary tree grows, with splitting plan as nodes and segments in the leave. 
\par
\rawdrawing{doom_map_split2}
\par
At this point in the splitting we are still not done. The area between \cw{B2}, \cw{C2}, \cw{F}, and \cw{F} is concave. We need one last split.\\ 
\par
\drawing{doom_map_split3}{}
\par
With all sub-sectors in the leave convex, the BSP construction ends. The number of vertices and segments to deal has increased by 50\% but we now have a data structure capable of sorting all segments, from any point of view, at the cost of only three comparison.\\
\rawdrawing{doom_map_split4}
\par
This is only one of the many possible trees which could have been generated with the map. Choosing splitters in an alphabetical order would have produced an inefficient BSP.\\




\rawdrawing{doom_map_bad}{}
\par

\subsubsection{Usage}

\begin{wrapfigure}[10]{r}{0.5\textwidth}
\centering
\includegraphics[width=.5\textwidth]{drawings/doom_map_walk.pdf}
\end{wrapfigure}
To use the BSP, we only need to traverse it depth first and choose a branch based on a position on the map. Let's take two example using the BSP in figure XXX. For convenience of notation, sub-sectors have been labeled \cw{1} to \cw{4} and only the splitting lines are marked.\\
\par
From point of view \cw{P1}, traversing the BSP takes three tests. \cw{P1} is on the right of \cw{H}, on the left of \cw{G}, and on the left of \cw{F}. Which give the order near to far: \cw{1,2,3,4}. Notice that once the subsector is determined, it doesn't matter what order segments within a subsector are drawn since all subsectors are convex.\\
\par
From point of view \cw{P2}, traversing the BSP also takes three tests. \cw{P2} is on the left of \cw{H}, on the left of \cw{G}, and on the left of \cw{F}. Which give the order near to far: \cw{3,2,4,1}.\\
\par
The beauty of binary trees is that traversing them is a constant cost. No matter where we try to place the player on the map, it will always take three tests to sort all subsectors and their segments.
\pagebreak




\subsection{Binary Space Partitioning: Practice}
For \doom~, maps were preprocessed on a NeXTStation Turbo via the in-house tool node builder named \cw{doombsp}.\\
\par
For the tool to build the best BSP possible a splitter selection heuristic had to be established. A good splitter divides the map as evenly as possible (and therefore limit the depth of the tree) and is either horizontal or vertical (to be easier to debug).\\
\par
 \cw{doombsp} recursively inspect all lines in a subspace and give a splitting score to each of them. At the end of the evaluation, the highest scoring line is selected. Map is split in two and the process is repeated until only convex subsectors remain. This is a CPU intensive task which took XXXs for a E1M1 featured in Figure \ref{E1M1_lines}. And a total of XXX for all thirty maps of \cw{DOOM.WAD}.\\
\par
\drawing{E1M1_lines}{E1M1, a.k.a Episode 1 Map 1.}
\par
Figure \ref{E1M1_segs} shows the seven first splitters selected on E1M1. First level in red, second level in blue and the third level in green.\\
\par
Switching from sectors flooring to Binary Space Partition not only cost preprocessing time and frustration to map designers. There was a second side effect which was much more of an issue since it affected the players. Because the BSP sliced the map and created new vertices, wall positions was set in stone, there was no way to move walls.

\drawing{E1M1_segs}{Seven first splitters in the E1M1 BSP}
\drawing{E1M1_fab}{All subsectors at the end of E1M1 tree construction, each is a convex leaf.}

\par


\subsection{Drawing Walls}
With the expert knowledge of BSP in mind, let's take a look at the first step of a scene rendition. Namely, to render walls. As expected, \cw{R\_RenderBSPNode} traverses the binary tree in near to far order. Each sub-sectors leaves are sent down to the renderer via \cw{R\_Subsector}.\\
\par
\ccode{R_RenderBSPNode.c}
\par


To perform the side test, any geometry book will describe how to represent the plan with a parametric equation $$ P = P0 + t * (P1 - P0) $$
and use the power of the dot product to inject the coordinate of the test point, essentially projecting the point on a line perpendicular to the plan. The sign of the result tell if the point is in front or in the back of the plan.\\
\par
This technique is far from optimal since it requires either floating point or fixed point arithmetic. There is a better way which involves not the magic of the dot product but the awesomeness of the cross product.\\
\par
\ccode{R_PointOnSide.c}
\pagebreak


\begin{wrapfigure}[8]{r}{0.25\textwidth}
\centering
\includegraphics[width=.25\textwidth]{drawings/line_cross_product.png}
\end{wrapfigure}
Notice in the previous code listing how nodes are not stored as coordinate of two vertices (\cw{Point 1}, \cw{Point 2}) but rather as (\cw{Point 1}, \cw{Delta to Point 2}). This storage technique made the cross-product faster to generate since one of the vector (from the node) was already calculated.\\
\par


\subsubsection{Wall Projection}
We are now down in \cw{R\_Subsector} function where all segments in a subsectors are rendered in order. This part of the pipeline relies heavily on BAM (Binary Angular Measurement) where degrees in interval \cw{[0, 360]} are mapped in the full range of a 32-bit integer.\\
\par
\ccode{bam.c}
\par
The angle of both ends of the segment with respect to the player position are calculated. Segment with a negative angle (angleP2 - angleP2 < 0) are culled since they are not facing the camera. Segment passing the angle test are projected onto the screen via a double translation table. First the BAM is reduced from 32-bit to 13-bit. Then the angle is injected into a lookup table \cw{viewangletox} to give a screepspace \cw{X} coordinate.\\
 \par

\pngdrawing{projectionExplained}{}
\par
\cw{viewangletox} is generated to give the player 90 degree angle of vision and project to the border of the screen anything else. 
\par
\pngdrawing{angletoxTable}{}
\par
%With the sector floor and height a column dimension and vertical offset are calculated. With the distance to the player, scaling is applied. 
At this point the engine has calculated the screen space \cw{X} coordinates of both ends of a segment. But it is not time to draw yet. A little bit of clipping must occur. 






\subsubsection{Wall Clipping}
Here the code branch depending on two types of segments which can be encountered in a subsector. There are segments with only one side (connected with only one sector) which are opaque and have only a "middle texture". I call these "walls". There are segments with two sides (connecting two sectors) which are often transparent with no middle texture but with an "upper texture" and a "lower texture". I call these "portals".\\
\par
Clipping is a two steps process happening in screen space. The first, crude, step is horizontally based. Only walls affects the horizontal occlusion array but all segments are clipped against it.\\
\par
The second, fine, step is vertically based. Both walls and portals affects the vertical occlusion array and both are clipped against it.\\
\par
\pagebreak









\subsubsection{Horizontal Crude Wall Clipping}
The first clipping pass maintains a \cw{solidseg} array which keeps track of the walls horizontal occlusion. Since portals can be seen through, they have no impact on \cw{solidseg}. Segments entering this step come out as segment "fragments" since they may be split due to occlusion.\\
\par
\ccode{hclipper.c}
\par
Let's take a simple example and proceed step by step. In the room below, the player is facing north and four walls (\cw{A}, \cw{B}, \cw{C}, and \cw{D}) need to be rendered.\\
\par
\rawpngdrawing{clip_map}
\par

Initially the occlusion array has two entries, one representing what is on the left of the screen, from infinity to -1 and one on the right of the screen from 320 to infinity.
\par 
\begin{minipage}{0.54\textwidth}
\vspace*{2.5mm}
\ccode{clip0.c}
\end{minipage}
\begin{minipage}{0.46\textwidth}
\srawpngdrawing{0.95}{clip0}
\end{minipage}
\par






The first wall is rendered. There is nothing to occlude it and it is in the middle of the screen. A entry is added to represent the occlusion state.
\par
\begin{minipage}{0.54\textwidth}
\vspace*{2.5mm}
\ccode{clip1.c}
\end{minipage}
\begin{minipage}{0.46\textwidth}
\centering
\srawpngdrawing{0.95}{clip1}
\end{minipage}
\par



The second wall is rendered. Its left side is clamped via angle adjustment and the right side if not occluded. Since it touch the left edge of the screen no entry in the occlusion array is added.
\par
\begin{minipage}{0.54\textwidth}
\vspace*{2.5mm}
\ccode{clip2.c}
\end{minipage}
\begin{minipage}{0.45\textwidth}
\centering
\srawpngdrawing{0.95}{clip2}
\end{minipage}
\par





The third wall is rendered. It happens to lie just next to the second wall. It is fully converted to a wall fragment and nothing is discarded. The occlusion array is updated.
\begin{minipage}{0.54\textwidth}
\vspace*{2.5mm}
\ccode{clip3.c}
\end{minipage}
\begin{minipage}{0.46\textwidth}
\centering
\srawpngdrawing{0.95}{clip3}
\end{minipage}
\par


Finally the last wall is rendered. While occluded against the array, it is slipt into two fragments. The occlusion array is updated. All segment ended up touching each others. 
\begin{minipage}{0.54\textwidth}
\vspace*{2.5mm}
\ccode{clip4.c}
\end{minipage}
\begin{minipage}{0.46\textwidth}
\centering
\srawpngdrawing{0.95}{clip4}
\end{minipage}
\par
Notice how little RAM was used to maintain the occlusion state and how fast it is to check if the fullscreen is occluded. All the engine has to do is to check the array is size 1 and that the range goes from -infinity to +infinity.


\subsubsection{Vertical Fine Wall Clipping}
The second pass clips segments fragments vertically. A data structure based on two arrays as wide as the 3D canvas is maintained. It describes how much screenspace is still available for each column in the canvas.\\
\par
 Each segment rendered updates the structure by making \cw{ceilingclip} increase up  and \cw{floorclip} decrease down. A column is considered fully opaque when \cw{ceilingclip} height and \cw{floorclip} height are equal to each others. Walls fragments will mark a column as completely occluded while portals fragments will only update the occlusion columns with what their actually cover in screenspace.\\
\par
\ccode{vclippers.c}
\par
Let's take the example of a simple room made of three sectors (\cw{1},\cw{2}, and \cw{3}) connected by two portals (\cw{B} and \cw{F}) and surrounded by walls. Sectors \cw{1} and \cw{3} have the same ceiling and floor height but \cw{2} is set to have a higher floor and lower ceiling to it looks like a window.\\
\par

\begin{wrapfigure}[16]{f}{0.45\textwidth}
\centering
\includegraphics[width=.45\textwidth]{drawings/vcclip_map.pdf}
\end{wrapfigure}


Subsectors are rendered near to far in order \cw{1}, \cw{2}, and \cw{3}. Which means segments \{\cw{A}, \cw{B}, \cw{C}, \cw{D}\}, \{\cw{E}, \cw{F}\} and \{\cw{G},\cw{F}\} (assuming the map was split on line \cw{B} and \cw{F}). On the opposite page you can see the effect of each wall and portals on the vertical occlusion double array.\\
\par
Walls \cw{A}, \cw{E}, \cw{C}, and \cw{D} mark the full height opaque for each of their columns. The first portal \cw{B} has no middle texture. It is therefore rendered with its upper texture (to accommodate for subsector 2 lower ceiling) and its lower texture (to accommodate for subsector 2 higher floor) and adjust the occlusion array accordingly.\\
\par
Notice how portal \cw{F} which lower and upper texture are not rendered still updates the occlusion array. Walls \cw{G} and \cw{H} finish marking the full screen opaque (but were only clipped during the crude pass since they are smaller than the visible window space).


\fullimage{simple_room.png}

% \vspace{3mm}

Blablablba bla.

\vspace{2mm}
 

\fullimage{simple_room_clip}














During the vertical clipping step, walls and portal screenspace coordinate are completed. For each fragment ends, n \cw{Y} offset is calculated based on sector floor and a column height is generated based on floor/ceiling and distance. These are interpolated to generate a set of full columns of pixels (portals are drawn as a combination of columns according to their upper texture, middle texture, and upper texture while walls are only middle texture). Rendition is done via \cw{colfunc} function pointer (detailed in the "performance" page XXX).\\

\par
\subsection{Drawing Flats}
 If we were to take a look at the framebuffer at this point in the rendition of a frame, it would look like mashed potatoes (see opposite page where flats are in white to ease visualization. Doom never clears the framebuffer so instead of white there would be whatever was there last frame.).\\
\par
To render the flats, the engine uses a database generated while walls and portals were being rendered. A database made of what is called "visplanes".\\
\par
\ccode{visplanes.c}\\
\par
The concept of visplane is the most difficult aspect of \doom to understand. The comments in the source code manifest of their esoteric nature and also attests that even people closely related to id Software did not fully grasp what they were.\\
\par
A visplan describes in screen space an area representing either a ceiling or a floor. It had a height, a texture (\cw{picnum}), and a light level. To describe the limits of its area, it has two array as wide as the screen. Areas are represented as a set of column with one column possible per \cw{X} coordinate.
\par


\fullimage{mashed_potatoes1.png} \label{mashed_potatoes1.png}

Above, the final frame. Below, the current state of the frame with missing visplanes.

\vspace{2mm}
\fullimage{mashed_potatoes2.png}


\trivia{Visplane rendition is deferred. They had to be stored while walls were rendered. 664 bytes per visplane (and 128 visplanes) represented a significant amount (84,992 bytes) for a game limited to 4MiB.}\\
\par
Visplan represent the screen space vertical "gaps" between fragments and screen border or between walls and portals. To understand better how they are generated, let's take and example and go back to the simple room we just studied. This time we will focus on how the \cw{visplanes} array is populated.\\
\par

\begin{wrapfigure}[16]{r}{0.45\textwidth}
\centering
\includegraphics[width=.45\textwidth]{drawings/vcclip_map.pdf}
\end{wrapfigure}
Like in the previous example, segments are rendered near to far in the following order: \cw{A}, \cw{B}, \cw{C}, \cw{D}, \cw{B}, \cw{E}, \cw{F}, \cw{G}, and \cw{H}.
When wall \cw{A} is rendered, it is clipped horizontally and vertically. Since it use all the vertical space, no visplane is created.\\
\par
 Things get slightly more interesting when walls \cw{C} and \cw{D} are rendered. Since they do not occupy the full height (there is a gap between the screen and the top/bottom edge of the walls), two visplanes per fragments \cw{1}, \cw{2}, \cw{3}, and \cw{4} are created and stored in the visplane array.\\
 \par
  Likewise when portal \cw{C} is rendered, there are gaps above its upper texture and below its lower texture, so two visplanes additional visplanes (\cw{5} and \cw{6}) are added.\\
\par
Wall \cw{E} is an other new case. The gap above and below are not between a wall and the screen but between  \cw{E} and the portal \cw{C} upper and lower parts. To detect the previous boundaries, the vertical occlusion array seen previously is used to create \cw{7} and  \cw{8}.\\
\par
Portal \cw{F} is yet an other special case. Since from this point of view it is connecting to a sector with higher ceiling, connecting to a sector with lower floor and has no middle texture, nothing is rendered. Yet the coordinates of its middle part are still generated in order to generate visplanes \cw{9} and  \cw{10}.\\
\par
Fron this point on, this is the same process over and over again. Wall \cw{G} rendition generates visplanes \cw{11} and  \cw{12} and Wall \cw{H} rendition generates visplanes \cw{13} and  \cw{14}.\\
\par
This algorithm generates a lot of visplanes and consume a lot of RAM. To address this issue, \doom merges visplanes.









\fullimage{simple_room_visplanes}

% \vspace{3mm}

Below, the engine was modified to draw walls and flats in plain color to show merging.

\vspace{2mm}
\fullimage{small_room_visplanes.png}




\fullimage{complex_scene_plain_light.png} \label{complex_scene_plain_light.png}

% \vspace{3mm}


E1M1 benefits from merging. Reproduced below without diminished lightning for clarity.

\vspace{2mm}
\fullimage{complex_scene_plain.png}



\fullimage{complex_scene_multivis.png}

% \vspace{3mm}

Without merging (above) the frame required 179 visplanes. With merging (below), only 28.

\vspace{2mm}
\fullimage{complex_lowvis.png}


On the previous page, the modified engine shows how a visplane does not need to be horizontally continuous. The red floor visplane for example is made of three parts yet just use on entry in the visplane array, validating the judicious choice to represent visplanes as array of columns\footnote{It would have been easy to use an array of lines since visplanes are rendered as lines.}.\\
\par
There are several conditions required to merge two visplanes. Mergable visplanes must have the same height, light and texture. Even if these conditions are met, the datastructure has to be able to absorb each others. This is only possible if visplanes are side by side. Even one pixel above or below with the same \cw{X} coordinate make two visplanes ineligible for merging. Function \cw{R\_FindPlane} looks for candidate, mergability is tested elsewhere.\\
\par
\ccode{visplane_linear_search.c}
\par
Notice the overflow check which modders feared more than anything since it terminated execution. The error message was less not helpful in figuring out what was wrong and how to fix the map. Many legends and theories circulated until the source code was released. 





\subsection{Drawing Flats (For Real)}
We can finally read the flat drawing routine (\cw{R\_DrawPlanes}) which simply iterates over the array of visplanes.\\
\par
\ccode{R_DrawPlanes.c}
\par
Notice how the flat texture resource is not freed at the end of each iteration but rather marked as \cw{PU\_CACHE} accordingly to what was described in the memory manager section.\\
\par
It may seem odd that each visplane is converted into lines (called \cw{spans} in the code) since walls were rendered as columns. This is to optimize the process of something we have ignored so far in order to introduce complexity progressively. It is diminished lighting.






\trivia{The limitation on 128 visplanes was not only necessary to fit within the memory budget, it was also a runtime necessity. When attempting to merge visplanes, the engine search complexity algorithm based on a linear search, making it a $O(n^})$ operation which would become a bottleneck as the number of visplanes increased. In 1997, Lee Killough lifted this limitation, replacing linear search with a $O(1)$ chained hash table\footnote{Source: "The Truth about Visplane Overflows".}.




























\subsection{Diminishing Lighting}
\label{diminishedlightning}
\begin{wrapfigure}[11]{r}{0.33\textwidth}
\centering
\scaledimage{0.33}{palette.png}
\end{wrapfigure}
So far, in order to introduce complexity gradually, our trip down the rendering pipeline has completely ignored diminishing lighting. It was assumed that values from texture and sprites texels were used as is and written directly to the framebuffer. Now it time to introduce the concept of lightmaps.\\
\par
In order to convey a scary atmosphere, \`a la Aliens, it was decided since day one that with increasing distance, colors would fade to black. Map designers also wanted to be able to switch the light in a room on and off but also dim it if necessary. To response to this requirement, the engine had to be able to draw shades of a color. With a VGA system limited to 256 colors from a palette, a possible implementation would have been to restrict artist to use 16 colors and use the 245 other slots to generate 15 shades of each "primary" colors.\\
\par
This would have severely impaired the work of the artist, not to mention it would have looked poor during outdoor scene where light is not diminished with distance. Once again a clever trick was to allow artists to use the full 256 colors for their assets and not 16 but 32 shades of the same color. One paper that would have meant $256 * 32 = 8192$ colors ... which the VGA did not have.\\
\par
 The trick to fake more colors than available is to use an indirection "light table" where the other 255 colors are used to approximate a gradient of each 256 entries. The lightmap is 256 entries tall (one for each index) and 32 wide (one column for each shade). In figure \ref{COLORMAP.png} you can see how the original palette lines are unrolled vertically in the left most column (notice the isolated white at the top and the pink at the bottom). Each row is a 32 values gradient toward black, using the same 256 colors. The right most column is all black. The trick has its limits. It works well for red but not too well for crimson and yellow.\\
 \par
 To use the lightmap, take the original texel value \cw{T} which is between [0,255]. This will be the \cw{X} coordinate. Take a light value \cw{L}, with 0 being the brightness and 31 being the darkest. This will be the \cw{Y} coordinate. The value to write in the framebuffer is \cw{lightmap[X][Y]}.\\
 \par
\cscaledimage{1}{COLORMAP.png}{The \cw{COLORMAP} is 32 shades of 256 colors yet still 256 colors total.}





\fullimage{diminishedlight2.png}

Above, normal engine (without sprites). Below same scene with lightmaps disabled.
\vspace{2mm}

\fullimage{diminishedlight1.png}


\cfullimage{diminishedlight3.png}{\doom engine with texture disabled and no sprites}
\par
The visual effect of lightmaps can sometimes be subtle. On the opposite page, a normal scene (above) shows no banding. Disabling lightmap altogether (opposite page, below) makes the colors appear washeout. Disabling texturing by rendering walls in white (\cw{0x04}) and flats in brown (\cw{0x80}) (as in figure \ref{diminishedlight3.png}) makes lightmaps apparent.\\
\par
Because calculating which lightmap to use is based on the distance from the player and also on the sector light level, it is a slightly expensive operation.\\
$$ lightmapId = sectorLightLevel + z * diminishingFactor $$
$$   color = lightmapId[textureTexel] $$
\par
 To reduce lightmap arithmetics, the scene drawing is dictated by where the lightmap value is constant. Walls are drawn as columns and flat are drawn as lines. Lightmap calculation are cached for flats. Since a visplane can be horizontally discontinue, \\
 \par
 Walls are twicked a bit. Vertical lightmap--, horizontal++. Diagonal untouched.\\
\pagebreak



\trivia{Lightmap \cw{COLORMAP} contains a 32th column made of 256 shades of grey. It is used when the player picks up the invulnerability bonus. However there is a bug in the visplane rendition routine special case in charge of skies. It forgot to account for lightmaps. Skies are always rendered normally}\\
\par 
\ccode{lightmap.c}
\par
\fullimage{invulnerable.png}\\
\par
\trivia{
Each portion of the sky are stored in visplanes and drawn as span of pixels. A sector just have a special ceiling texture number which the engine recognize in which case, height is 0, lightmap is 0 and perspective is disabled ot the sky is rendered flat on the canvas.}\\




\fullimage{idbeholdv.png}
\par
This effect was diffcult to replicate with hardware accelerated system which use 24-bit colors. On iOS, \cw{glBlendFunc(GL\_ONE\_MINUS\_DST\_COLOR, GL\_ZERO)} was used.\\
\par
\fullimage{invOpenGL.png} 














\subsection{Drawing Masked}
With the environment rendered, what remains are "masked" elements. This category emcomparse not only all sprites but also partially transparent walls and also the player's hand.\\
 \par


\scaledimage{0.25}{cacodemon1.png}\scaledimage{0.25}{cacodemon2.png}\scaledimage{0.25}{cacodemon3.png}\scaledimage{0.25}{cacodemon4.png}\\

\scaledimage{0.25}{cacodemon9.png}\scaledimage{0.25}{cacodemon10.png}\scaledimage{0.25}{cacodemon11.png}\scaledimage{0.25}{cacodemon12.png}\\

\scaledimage{0.25}{cacodemon17.png}\scaledimage{0.25}{cacodemon18.png}\scaledimage{0.25}{cacodemon19.png}\scaledimage{0.25}{cacodemon20.png}\\

\scaledimage{0.25}{cacodemon25.png}\scaledimage{0.25}{cacodemon26.png}\scaledimage{0.25}{cacodemon27.png}\scaledimage{0.25}{cacodemon28.png}\\
\pagebreak


The function responsible for this task is called \cw{R\_DrawMasked}. It is the last step in the rendering pipeline. Contrary to the environment which is rendered in front to back order, this step proceeed in back to front (which is the only way to get transparency right).\\
\par
\vspace{2mm}
\scaledimage{0.25}{cacodemon5.png}\scaledimage{0.25}{cacodemon6.png}\scaledimage{0.25}{cacodemon7.png}\scaledimage{0.25}{cacodemon8.png}\\

\scaledimage{0.25}{cacodemon13.png}\scaledimage{0.25}{cacodemon14.png}\scaledimage{0.25}{cacodemon15.png}\scaledimage{0.25}{cacodemon16.png}\\

\scaledimage{0.25}{cacodemon21.png}\scaledimage{0.25}{cacodemon22.png}\scaledimage{0.25}{cacodemon23.png}\scaledimage{0.25}{cacodemon24.png}\\

\scaledimage{0.25}{cacodemon29.png}\scaledimage{0.25}{cacodemon30.png}\scaledimage{0.25}{cacodemon31.png}\scaledimage{0.25}{cacodemon32.png}\\

\pagebreak






\begin{wrapfigure}[12]{r}{0.5\textwidth}
\centering
\includegraphics[width=.5\textwidth]{drawings/masked_map.pdf}
\end{wrapfigure}

Before diving into the function responsible for drawing masked elements, let's take a simple example to understand what needs to be done.\\
\par
 A simple room with four walls (\cw{A}, \cw{B}, \cw{C}, and \cw{D}), a pillar also made of four walls (\cw{E}, \cw{F}, \cw{G}, and \cw{H}), a transparent wall \cw{I}, a barrel (in grey, a player spawning point (in green) and three enemies (in red: a Baron of Hell, a Cacodemon, and a Demon).\\
\par
The result as rendered by \doom engine is visible in figure \ref{masked.png} Notice how the Baron is drawn on top of wall \cw{I}. How the Cacodemon is partially occluded by wall \cw{I}. How parts of the demon are completely clipped behind the pillar. Also notice how the barrel must be drawn in front of the Baron for correctness. Notice how wall \cw{I} needs to be clipped againt the pillar.\\
\par
\cfullimage{masked.png}{}
\par
With the target in mind, let's go back to where we were with walls and flats rendered in the framebuffer. In the case of the same room, it would look like \ref{masked_nomasked.png}.\\
\par
\cfullimage{masked_nomasked.png}{}
\par
To get from figure \ref{masked.png} to figure \ref{masked_nomasked.png}, the engine needs a list of maskable (also simply called sprites in the code), sort then in back to front order, iterate over the sorted list and for each of them perform clipping, and finally render them as columns of pixels.\\
\par
\subsubsection{List Of Things}
 The list of things was build while the BSP was traversed. Each time a subsector was sent to rendition (in \cw{R\_Subsector}) the list of things it contained were also added to an array of \cw{vissprite\_t}. Note that Things are pseudo-ordered and therefore the order is not usable. In our example the barrel and the baron would be added based on the subsector they were in, but in no precise order (in the subsector list of things, the baron could be returned before the barrel).\\
 \par
 \subsubsection{Clipping Information}
 The clipping information was also built while rendering walls. Anything that could potentially apperar on the screen was stored in an array of \cw{drawseg\_t}.\\
\par

The "drawn segments" array \cw{drawsegs} is made of the following \cw{drawseg\_t} struct.\\
\par
\ccode{drawseg_t.c}\\
\par
The array \cw{drawsegs} can be seen as a log of what was rendered to the screen.\\
\begin{itemize} 
	\item For each wall which generated pixels in the framebuffer, a \cw{drawseg\_t} is added.
	\item For each portal, up to two \cw{drawseg\_t} are added (one for the upper part and one for the lower part if there the portal had no middle texture).
	\item For each masked segments (like the grid \cw{I} in our example) which were skipped, one \cw{drawseg\_t} entry is added to record what should have been drawn.
\end{itemize}
A \cw{drawseg\_t} contains all the screenspace information to perform either clipping or rendering. There is a pointer to the line (\cw{curline} which contains the textureID), the screenspace horizontal boundaries (\cw{x1} and \cw{x2}) as well as their respective scale (\cw{scale1} and \cw{scale2}). Scale represent how magnified or minified a sprite should be. All sprites share the same unit and since scale is based on the distance from the player the engine uses it to compare \cw{z} distances.\\
\par
The screenspace horizontal top and bottom edge of a wall are obtained from pointers \cw{sprtopclip} and \cw{sprbottomclip} which point to an array shared by all \cw{drawseg\_t}.\\
\par
\ccode{openings.c} 
\pagebreak

\par
DRAWING OF OPENINGS DATABASE\\
\vspace{4.5cm}
\par
The visible sprites (\cw{visprites}) storage is considerably easier to understand than the drawn segment storage.\\
\par
\ccode{vissprites.c}
\par
A vissprite entry contains eveything need to render a sprite on screen. It features information similar to the drawn segments such as the screen space horizontal boundaries (\cw{x1} and \cw{x2}), its scale, its texture id (\cw{patch}) and the lightlevel (\cw{colormap}) to be used for shading.\\
\par
Notice the \cw{prev} and \cw{next} fields. Even though vissprite are stored in a linear array, they need to be sorted in back to front order. Instead of performing an expensive copy of all elements, the sorting method only updates the double linked list. This way all elements remain in the same position in the array but a sorted list can be obtained by follwoing the \cw{next} pointers.\\
\par

Let's finally look at how all these data are used to render the sprites and masked segments in \cw{R\_DrawMasked}.\\
\par
\ccode{R_DrawMasked.c}\\
\par
As expected, the list of visible sprites is sorted based on their distance to the player (\cw{R\_SortVisSprites}). This process is very fast since only \cw{scale} has to be compared and no data is copied, only the double linked list is updated.\\
\par
Next, all sprites are rendered one by one in a back to front fashion. The method taking care of this (\cw{R\_DrawSprite}) scans linearly the array of \cw{drawseg} to find what wall fragment was drawn in front of the sprite and clips it accordingly. Since the search is based on the scale of each \cw{drawseg\_t} and the screenspace \cw{X} boundaries it is a fast operation.\\
\par
The last step is to render the masked segments which were skipped during BSP traversal. This is done in method \cw{R\_RenderMaskedSegRange}. Notice that as explained (render all sprites then render all masked segments), there is no way the grid in figure  \ref{masked.png} could be interleaved with the sprites. To address this, there is a little "hack" in (\cw{R\_DrawSprite}) method during the linear scan for occluding \cw{drawseg\_t}. It detect which segment was a "masked" and skipped, and render them.\\
\par
\trivia{To speed up sprite rendition, sprites textures are stored and drawn as columns in order to please the Intel 486 cachelines.}\\
\par



\subsection{Drawing Masked Player}
The last piece to render is the easiest of all. The Player Sprite (\cw{psprite}) is drawn on top of everything. These is no clipping in effect here, only the need to account for the lightmap induced by the sector the player is currenyly standing in and making the hand wave left and right when moving/running.\\
\par
You may have notice in \cw{R\_DrawMasked} that the player hand is drawn only if the viewing angle is not equal to zero (\cw{viewangleoffset}). This is an artifact from a feature which was disabled before shipping. Until v1.2, \doom supported a "three screens mode" where three computers with three monitors could be running in network in order to render a wide field of view.\\
\par
\fullimage{three_screens_mode.png}
\par
It is likely this feature was inspired to John Carmack when he visited Alaska Airline training center where he was able to see a multi-million dollar wide screen flight simulator\footnote{Source: "http://leeland.stores.yahoo.net/earlydoomstuff.html"}. The visual quality was not satisfactory in the end and part of the code to enable it was promptly removed...but some part of the feature survived.\\
\par
% \trivia{Player has gloves when handling most weapons but he takes them off when using the point american.}\\

\subsection{Picture format}
Since sprites are written one vertical column at a time, they are stored in a way to cuddle the i486 cachelines during read operations. Each sprite is stored in its own lump and consist in a collection of line describing the vertical column in the sprite (in essence, sprites a stored rotated 90degres CCW).\\
\par
Each column (also called "post" in the code) is a set of "spans" with one byte giving the vertical offset where the span starts, then one byte giving the size of the payload and finally the texel payload.
\pagebreak

Row \cw{44} is 4 bytes (one span \cw{0xXX}, \cw{0xXX}, \cw{0xXX}, \cw{0xXX}). Row \cw{33} and \cw{10} are both made of two spans accounting respecitvely for XX bytes and XXX bytes. The entire Lost Soul sprite is 44x47 and fits in 1360 bytes.\\
\par
\fullimage{sprite_format.png}\\
\par

\subsection{Sprite aspect ratio}
The framebuffer was distored when transfered from the VGA to the CRT screen. It was not a striking difference for the walls and flats making the environement. For sprites however, the 4:3 aspect ratio makes pixels 33\% taller than they were wide, making sprites visibly stretched vertically.\\
\par
This distortion had not been an issue when working with Deluxe Paint since the tool could be setup in 320x200 (so artists did not have squared pixels) but it was something to factor in when id switched to using scanned image from the NextDimension.\\
\par
\cfullimage{sprites_ratio_demon.png}{Demon}
\par
The cacodemon was purposely drawn and rendered ellipctically but effectively stored as a rounded shape. Many asset extractors programmers never accounted for the CRT distortion.\\
\par
\cfullimage{sprites_ratio_cacodemon.png}{Cacodemon}
