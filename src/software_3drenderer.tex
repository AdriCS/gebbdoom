\section{3D Renderer}
The 3D renderer is an uncanny combination of proper 3D techniques and screen space tricks. Its most breathtaking characteristic is that it renders walls and flats with zero overdraw. The design is is amusingly orthogonal to Wolfenstein 3D renderer. The latter's ties to the VGA made it render everything vertically while \doom's 486 cachelines made it render things horizontally as much as possible.\\
\par
 For the environment, pixels in the framebuffer are all written exactly once\footnote{Sprites and Transparent walls do introduce a little bit of overdraw but it is minimal.}. It can be broken down in four sections dedicated to rendering walls, flats (ceilings and floors), transparent elements, and current weapon.\\
\par
The big lines are as follow:\\
\par
\begin{itemize}
\item Render walls segments, sorted near to far from the player point of view. Both wall ends are projected into screenspace axis X. Based on the distance and floor/ceiling the wall sectors belongs to, calculate a column Y offset and an height. 
\item To render a full wall, generate a set of columns to make ends meet. Interpolate height and Y vertical columns. While rendering:
   \begin{itemize}
     \item record screenspace vertical gaps between walls or between wall and screen boundaries. Infer ceiling (if above mid-screen) or floor (if below miscreen) and stored the area into an array of structure called "visplanes".
     \item Store sprites to be drawn into an array of struct "vissprites".
   \end{itemize}      
\item Render all ceiling and floors from the visplanes.
\item Render transparent elements in far to near order.
\item Render player sprite (overlay view).
\end{itemize}
\par
The different sections can easily be identified in the code.\\
\par
\ccode{R_RenderPlayerView.c}{}
\par
\trivia{Wolfenstein 3D and Doom have orthogonal architectures. Where the former tried to draw everything vertically to favor the VGA, the latter tried to draw everything horizontally to favor the 486 cachelines.}

\subsection{Walls}
There are two ways to render walls in a correct way. Either go with a painter algorithm which draw far to near and involves no book-keeping but generate a lot of overdraw. Or draw near to far, keeping track of what has been drawn which is more compicated but has zero overdraw. In both strategy lies the problem of sorting them according to the player point of view. Given the high cost of rendition, \doom went for the latter approach.\\
\par

\subsubsection{Sorting walls}
In its early instance the engine consumed exactly what the designer produced, namely lines and sectors. Starting in the sector containing the player, the engine would look for double sided lines and treat them as portals. Each portal lead to ajacent sector where the process was repeated recursively\footnote{That was the same design Ken Silverman's build engine would settle on to power Duke Nukem 3D. However in 1996 Pentium had taken over and were more than able to deal with complex polygons.}.\\
\par
DRAWING\\
\par
Most of the time it worked well. But when designers stated to build complex maps with staircases, performances collapsed like it in this early map made by John Romero for an alpha version.\\
\par
\cfullimage{SCREEN00.png}{Notice the HUD using a huge portion of the 3D canvas.} \label{HUD_screenshot}
\par
\fq{The engine was still built out of "sectors" -- complex polygonal regions with a common floor / ceiling texture and height, but it didnâ€™t have the BSP-chopped "subsectors".  It started in the view sector and recursively flowed into the adjourning sectors, but because they could all be complex polygons it was a lot of record keeping to know what parts you had already visited or were in the stack somewhere.  It worked, and simple areas were fast, but it slowed down precipitously with complexity.}{John Carmack}
\par
Concave and convex sectors proved to be too much complexity for the engine to deal with and maintain a descent frame rate. This was a huge issue. They did not have much time to work on it thought, since around the same time this issue was discovered, work on \doom had to stop in order to respond to an emergency.\\
\par
Back in June 1992, id had promised to deliver Wolfenstein 3D for SNES. They subcontracted the project and kinda forgot about it. Six month later they could not get in touch with the contractor. They had nothing to show to Nintendo and it was a big deal involving a huge penalty.  \doom development stopped completely and desperatly banged they old game together into a machine not remotely built to do what they wanted. While Tom Halls dusted of his 6502 assembly skills, John Carmack had a different kind of problem at hand, the raycasting technology which Wolf relied on was too much for the Nintendo console. The SNES and its 6503 on steroids simply did not have enough juice for the DDA algorithm\footnote{You can read everything about DDA in Game Engine Black Book: Wolfenstein 3D}. It turned out a white paper co-authored by Bruce Naylor would end up making a huge difference.\\
\par




\subsubsection{Binary Space Partitioning: Theory}
In early 1993, Bruce Taylor paid a visit to his friend at id Software. At that point, he had been working in the Computer Graphics field for nearly two decade at University of Texas. He did not come empty handed, he had brought with him many papers about CG. One of them was his own, published in 1988 for SIGGRAPH in collaboration with H.Futchs and Zvi Kedem. It was titled "ON VISIBLE SURFACE GENERATION BY A PRIORITI TREE STRUCTURES".\\
\par
The technique explained a favorable trade-off where a bit of preprocessing on a set of polygon allowed a formidable runtime speed up. The preprocessing was dead simple. By recursively spiting a space in two, any set of complex polygons could be transformed into a set of convex polygon associated with a navigable binary tree.\\
\par
\cfullimage{bsp_paper.png}{ON VISIBLE SURFACE GENERATION BY A PRIORITI TREE STRUCTURES}
\par
 \trivia{The paper mentions 1988 hardware, "moderately-priced (\$40,000-80,000) real-time line-drawing systems" capable of line drawing only. A good example of the improvement of performances within five years only.}\\
 \par

 \begin{verbatim}
In order to determine the visible surface at each pixel, traditionally
tile distance from the viewing position to each polygon which maps onto 
that pixel is calculated. Most methods attempt to minimize the number 
of polygons to be so considered. Our approach eliminates these distance
calculations entirely. Rather, it transforms the polygonal data base 
(splitting polygons when necessary) into a binary tree which can be 
traversed at image generation time to yield a visible priority z value
for each polygon.
\end{verbatim}

\par
\fq{When I did the early work on BSPs, Bruce Naylor came down and visited here and gave me copies of a bunch of his papers. It's interesting to talk to people about the old days. Of course, you've got the Internet now. You can find anything nowadays. But back then, it was really something to get reprints of old academic papers. There were some clearinghouses I used to use: you'd pay twenty-five dollars or whatever, and they'd mail you xeroxes of old research papers. It was just a very, very different world. I learned most of my programming when I had a grand total of like three reference books. You had to figure everything else yourself. So I was finding I was reinventing a lot of classic things, like Huffman encoding or LZW encoding. So I'd be all proud of myself for having figured something out, and then I'd find it was just classic method and they did it better than I did.}{John Carmack, Interview for Scarydarkfast}

\par
\subsubsection{Step by Step}
Let's take the example of a simple map which could have been drawn in DoomED. It features a single sector with a pillar inside it. Eight vertices and eight lines. Despite is simplicity it forms a difficult problem to solve to a renderer aiming at scene correctness. Depending on the player position the order in which the wall must be drawn will vary. \\
\par
\pngdrawing{doom_map}{}
\par
The science of Node building is to select the best splitting line. A list of poor choices would to select \cw{A}, then \cw{B}, then \cw{C} then \cw{D} which would accomplish nothing but to create a costy linked list with more data at the end.\\ 
\par
In the case where \cw{H} is chosen, the map is divided in two. Some line fit entirely on the right side of the spliting plan, some on the left. Line on both sides must be slit into segments.\\
\par
\pngdrawing{doom_map_split1}{}
\par
The process is repeated until the map is made of convex spaces. Notice how the binary tree grows, with splitting plan as nodes and segments in the leave. 
\par
\pngdrawing{doom_map_split2}{}
\par
After the last spliting operation, all segments in the leaves form a convex subspace called a Sub-Sector (\cw{SSECTOR}).\\
\par
\pngdrawing{doom_map_split3}{}
\par
Notice that this is only one of the many possible BSP tree which could have been generated. A different (yet reasonable) set of splitter would have given something different yet equivalent.\\
\par
\pngdrawing{doom_map_alternate}{}
\par
At first sight it may look like all these operations were counter productive. The map started with 8 lines and now it has twelve which is 50\% more work. But by using the binary tree the entire scene can be sorted in only three tests regardless of the player position.
\par
EXAMPLE, PLAYER in SSector 1\\
\par
EXAMPLE, PLAYER in SSector 2\\





\subsubsection{Binary Space Partitioning: Practice}
Input:\cw{LINE} and \cw{SECTOR} figure XX.\\
Output:\cw{SEG} and \cw{SSECTOR} and \cw{NODE} figure YY.\\
TODO: How long did it take to preprocess all maps?\\
\par
If the cost of preprocessing map was invisible to players and only affected designers, there was a second side effect which was much more of an issue. Because the BSP sliced the map, wall position was set in stone, there was no way to move. Floor and ceiling levels remained unaffected.\\
\par
Only after April 1993, when the team had to do Wolfenstein 3D within three weeks, did the engine renderer change.\\

\ccode{R_RenderBSPNode.c}
\par

\subsubsection{Binary Space traversing}
The theory to traverse a binary tree is straight forward. Recursively determine on what side of a plan a point is. To perform the side test, any geometry book will describe how to represent the plan with a parametric equation $$ P = P0 + (P1 - P0) * t$$
and use the power of the dot product to inject the coordinate of the test point, essentially projecting the point on a line perpendicular to the plan. The sign of the result tell if the point is in front or in the back of the plan.\\
\par
This technique is far from optimal in the context of \doom for the simple reason it requires either floating point or fixed point arithmetic. There is a much better way which involves not the magic of the dot product but the awesomeness of the cross product.\\
\par
\pngdrawing{line_dot_product}{}
\pngdrawing{line_cross_product}{}


\ccode{R_PointOnSide.c}

\subsubsection{Wall projection}
BAM\\
\par
\ccode{bam.c}
\par
\pngdrawing{projectionExplained}{}
\par
\pngdrawing{angletoxTable}{}







\subsubsection{Wall clipping}
As segments are elected for rendition in a back to front order, they must be clipped before they reach the rasterizer. Clipping is done in two steps using an horizontal occlusion array and a vertical occlusion structure.\\
\par
The first crude pass maintains a solidseg array which keeps track of which part of the screen received wall segment. Segments can be completely rejected or split into multiple fragments. Note that since they allow things to be drawn behind them, portal segment have no impact on the horizontal occlusion array.\\
\par
Ceiling start at -1 while floor start at viewheight (namely XXX).
\par
\ccode{hclipper.c}
\par
It is easier to use an example and proceed step by step. In the room below, the player is facing north and four walls need to be renderered.
\par
\pngdrawing{clip_map}{}
\par

Initially the occlusion array has two entry, one representing what is on the left of the screen, from infinity to -1 and one on the right of the screen from 320 to infinity.\\
\par 
\begin{minipage}{0.54\textwidth}
\centering
\ccode{clip0.c}
\end{minipage}
\begin{minipage}{0.46\textwidth}
\centering
\srawpngdrawing{0.95}{clip0}
\end{minipage}
\par






The first wall is rendered. There is nothing to occlud it and it is in the middle of the screen. A entry is added to represent the occlusion state.\\
\par
\begin{minipage}{0.54\textwidth}
\centering
\ccode{clip1.c}
\end{minipage}
\begin{minipage}{0.46\textwidth}
\centering
\srawpngdrawing{0.95}{clip1}
\end{minipage}
\par



The second wall is rendered. Its left side is clamped via angle adjustment and the right side if not occluded. Since it touch the left edge of the screen no entry in the occlusion array is added.
\par
\begin{minipage}{0.54\textwidth}
\centering
\ccode{clip2.c}
\end{minipage}
\begin{minipage}{0.45\textwidth}
\centering
\srawpngdrawing{0.95}{clip2}
\end{minipage}
\par





The third wall is rendered. It happens to lie just next to the second wall. It is fully converted to a wall fragment and nothing is discarded. The occlusion array is updated
\begin{minipage}{0.54\textwidth}
\centering
\ccode{clip3.c}
\end{minipage}
\begin{minipage}{0.46\textwidth}
\centering
\srawpngdrawing{0.95}{clip3}
\end{minipage}
\par


Finally the last wall is rendered. While occluded against the array, it is slipt into two fragments. The occlusion array is updated. All segment ended up touching each others. 
\begin{minipage}{0.54\textwidth}
\centering
\ccode{clip4.c}
\end{minipage}
\begin{minipage}{0.46\textwidth}
\centering
\srawpngdrawing{0.95}{clip4}
\end{minipage}
\par
Notice that portal are also clipped against the occlusion array but do not update it since walls/portal behind can be seen thought it. The occlusion array allows crude reject at a cheap cost. It also allow to test if the full screen is occlude with a simple test. Offers reduced write and read.\\
\par
The second pass clips fragment vertically. A data structure based on two arrays as wide as the 3D canvas is maintained. Each portal segment updates the vertical occlusion array. At the end of this step, fragments are converted into columns which are passed to the rasterizer \cw{colfunc()}\\
\par
\ccode{vclippers.c}
\par



\subsubsection{Wall drawing}
Interpolation
\trivia{To play nicely with cachelines (at least for read operations), texture data are stored as column major (rotated 90degrees left).}













\subsection{Flats}
At this point in the rendering pipeline, the framebuffer \#1 looks like mashed potatoes. A scene that would end up looking this way:\\
\par
\fullimage{mashed_potatoes1.png}
\par
As been partially drawn like this:\\
\fullimage{mashed_potatoes2.png}
\par

 All walls are correct but there are huge gaps in between which need to be filled. This is where the visplanes are used. How floors and ceilings are drawn is the most difficult part to understand. The puzzled command in the source code "Now what is a visplane, anyway?" tells a lot about the mystery surrounding them.\\
\par
\ccode{visplanes.c}
\par
In a nutshell, a visplane stores the screen space area of a ceiling or a floor which needs to be drawn. A modified version of the engine, drawing visplane in plain color help to visualize them.\\
\par
\fullimage{doom_visplanes.png}{}\\
\fullimage{doom_visplanes_colored.png}{} 22 visplanes
%\fullimage{doom_visplanes_colored_merged.png}{} 6 visplanes
\par
The previous screenshot was slightly misleading in order to ease comprehension. There are fourteen visplanes in that screenshot which is a lot for a simple room with a window. It is a problem in terms of memory consumption since a \cw{visplane\_t} struct is no less than 664 bytes. 9 KiB off storage for such a simple screen but imagine a scene with a staircase and two windows and the number of visplane could easily climb to 100s which would consum way too much for a game already struggling to fit into 4 MiB.\\
\par
To solve this problem, the engine merges visplanes as they are encountered. If two visplanes share the same texture, height, light intensity and if they don't overlad vertically, they are merged. In the previous example this brings the fourteen visplanes figure down to five.\\
\par
\fullimage{doom_visplanes_colored.png}{}
\fullimage{108visplanes.png}{}

\par
\begin{verbatim}
sizeof(visplane) = 664
(664) * 128 = 84992
framebuffers
\end{verbatim}
\fullimage{many_visplanes.png}




















\subsection{Visplanes and DrawPlanes overflow}
Even with visplane merging, the number of visplanes could still get out of hand. Storage was not dynamic, it was capped at 128 units. If the engine encountered condition where 129 visplanes were required it would quit with the following mysterious message:\\
\begin{verbatim}
"R\_FindPlane: no more visplanes"\\
\end{verbatim}
\par
R\_DrawPlanes: visplane overflow (\%i)\\
R\_DrawPlanes: drawsegs overflow (\%i)\\
R\_DrawPlanes: opening  overflow (\%i)"\\
\par

\trivia{The limitation on 128 visplanes was not only necessary to fit within the memory budget, it was also a runtime necessity. When attempting to merge visplanes, the engine search complexity algorithm based on a linear search, making it a $O(n^})$ operation which would become a bottleneck as the number of visplanes increased. In 1997, Lee Killough lifted this limitation, replacing linear search with a $O(1)$ chained hash table\footnote{Source: The Truth about Visplane Overflows}.
\par
\ccode{visplane_linear_search.c}




\subsection{Diminishing Lighting}
\begin{wrapfigure}[11]{r}{0.33\textwidth}
\centering
\scaledimage{0.33}{palette.png}
\end{wrapfigure}
So far our trip down the rendering pipeline assumed that values from the texture and sprite texels were used as is, indexing colors from the palette. That made things easier to understand but now is time to introduce diminished lightning.\\
\par
With the VGA, the mode Y allowed only 256 colors but as it turned out there was a smart way to fake more colors than available. Artists were allowed to use the full 256 primary colors and still get 32 shade of each without requiering $256 * 32 = 8192$ colors.\\
\par
 The trick to fake more colors than available is to reorganize the initial palette of 256 colors and for each values, try to use one of the other 255 available to fake 32 shades toward black. For some colors like skin, red, green, grey, brown or red it worked very well. For others not so much but given the speed of the game the human eye was forgiving.\\
 \par
 The trick implementation starts with a lump called \cw{COLORMAP} which looks like figure XX. The original palette indexes are unrolled in the first column. Fifteen additional columns are appended to the left of each colors. Notice that even though it may look like it has more, figure XXX only features 256 colors.\\
\par
In the source code, each column is refered to as a "lightmap". Before drawing starts, a lightmap column pointer is selected which acts as an indirection layer between the color in the asset and the shaded color to be rendered.\\
\par
\ccode{lightmap.c}
\par
The lightmap selection algorithm is different based on one of the three types of things renderered.\\
\par
\begin{itemize}
\item Wall. dc\_colormap = walllights[index]; where index 
\item Flat: start at sector light level [0,16] -> planezlight. index based on distance [0,128] ds\_colormap = planezlight[index];\\ lighttable\_t*    zlight[LIGHTLEVELS][MAXLIGHTZ]; How is zlight initialized?
\item Masked.
\end{itemize}
\par
\cscaledimage{1}{COLORMAP.png}{COLORMAP and its 32 lightmaps.}
\par




\begin{wrapfigure}[9]{r}{0.40\textwidth}
\centering
\scaledimage{0.40}{invOpenGL.png}
\end{wrapfigure}
Trivia: \cw{COLORMAP} contains a 17th lightmap made of 256 shades of grey. It is used when the player picks up the invulnerability bonus. This trick turned out to be a nightmware to replicate when developers ported \doom to hardware accelerated machines which where RGB based and not palette based. With OpenGL an exotic \cw{glBlendFunc(GL\_ONE\_MINUS\_DST\_COLOR, GL\_ZERO)} was usually attempted to give a result that was pretty close.
\par
Play with:
\begin{verbatim}
player->fixedcolormap
\end{verbatim}

TODO: With and witout screenshot\\
\par
TODO: With and witout screenshot2\\
\par
trivia: colormap hacks. Doom EGA and Doom CGA.\\

\section{Door}
Door code to make them open horizontally.
\section{Texture Mapping}
Persepctive correct was too expensive. But since only one axis had to be corrected, there was a way to get away with fast affine texture mapping.\\
https://www.doomworld.com/forum/topic/86977-doom-affine-texture-mapping-edition/\\
\par



\section{Masked}
Things, masked walls and player sprite.\\

\null\newpage % Make toc appear on right side
\par
\begin{minipage}{\textwidth}
\scaledimage{0.25}{cacodemon01.png}\scaledimage{0.25}{cacodemon02.png}\scaledimage{0.25}{cacodemon03.png}\scaledimage{0.25}{cacodemon04.png}\\
\scaledimage{0.25}{cacodemon10.png}\scaledimage{0.25}{cacodemon11.png}\scaledimage{0.25}{cacodemon12.png}\scaledimage{0.25}{cacodemon13.png}\\
\scaledimage{0.25}{cacodemon}\scaledimage{0.25}{cacodemon}\scaledimage{0.25}{cacodemon}\scaledimage{0.25}{cacodemon}\\
\scaledimage{0.25}{cacodemon}\scaledimage{0.25}{cacodemon}\scaledimage{0.25}{cacodemon}\scaledimage{0.25}{cacodemon}\\
\end{minipage}
\pagebreak
\begin{minipage}{\textwidth}
\scaledimage{0.25}{cacodemon05.png}\scaledimage{0.25}{cacodemon06.png}\scaledimage{0.25}{cacodemon08.png}\scaledimage{0.25}{cacodemon09.png}\\
\scaledimage{0.25}{cacodemon}\scaledimage{0.25}{cacodemon}\scaledimage{0.25}{cacodemon}\scaledimage{0.25}{cacodemon}\\
\scaledimage{0.25}{cacodemon}\scaledimage{0.25}{cacodemon}\scaledimage{0.25}{cacodemon}\scaledimage{0.25}{cacodemon}\\
\scaledimage{0.25}{cacodemon}\scaledimage{0.25}{cacodemon}\scaledimage{0.25}{cacodemon}\scaledimage{0.25}{cacodemon}\\
\end{minipage}

\par

\subsection{Things}
\begin{verbatim}
vissprite_t	vissprites[MAXVISSPRITES];

typedef struct vissprite_s {
    
    struct vissprite_s*	prev; // Doubly linked list.
    struct vissprite_s*	next;
    
    int			x1;
    int			x2;
    
    fixed_t		gx; // for line side calculation
    fixed_t		gy;		

    fixed_t		gz; // global bottom / top for silhouette clipping
    fixed_t		gzt;

    fixed_t		startfrac;     // horizontal position of x1
    
    fixed_t		scale;
        
    fixed_t		xiscale;	 // negative if flipped

    fixed_t		texturemid;
    int			patch;

    // for color translation and shadow draw,
    //  maxbright frames as well
    lighttable_t*	colormap;
   
    int			mobjflags;
    
} vissprite_t;

// While wall rendering, generate structure able to build a sprite clipping.
drawseg_t	drawsegs[MAXDRAWSEGS];
drawseg_t*	ds_p;

short clipbot[SCREENWIDTH];
short cliptop[SCREENWIDTH];

\end{verbatim}

Clipping is done via \cw{drawseg\_t	drawsegs[MAXDRAWSEGS];} array which is as big as the max \# of walls rendered.\\
\par
Drawing is done as columns: \cw{R\_DrawMaskedColumn}. Sprites are stored to please cachelines in reading.







\subsection{Weapon}

\subsection{Pot pourri}
The early 1993 press release written by Tom Halls (see Annexe page \pageref{label_press_release}) made some bold statements. Besides promising the best game of all time, it was remarquably accurate with regards to features the 3D renderer would end up shipping with:\\
\par
\par
Some of the annouced features had already been achieved by John Carmack. The game engine he had written during his research and licensed to Shadowcaster\footnote{See more details about Shadowcaster on page \pageref{label_shadowcaster}.} featured a fully texture mapped environement including flats (walls and ceilings). Light dminishing was also relatively easily implemented. However non-orthogonal walls was a big promise.\\
\par
DETAIL WOLF3D\\
\par
To lose fast intersections with aligned axis was a big problem. Not only drawing a scene correctly was going to be difficult, also gone were collision detection, sound propagation, and fast line of sight for monster I.A simulation.\\
\par
\trivia{Three Screen Mode}
